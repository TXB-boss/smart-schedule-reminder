import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import time
from thefuzz import process, fuzz
import random
import altair as alt
from openai import OpenAI
import os

# Page Configuration
st.set_page_config(
    page_title="æ ¡å›­è¯¾ç¨‹è¡¨æ™ºèƒ½åŠ©æ‰‹",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS to hide/translate English elements
st.markdown("""
<style>
    /* å°è¯•éšè— File Uploader çš„è‹±æ–‡æç¤ºå°å­— */
    [data-testid="stFileUploader"] small {
        display: none;
    }
    /* å¢åŠ ä¸€äº›åœ†è§’å’Œé˜´å½± */
    .stCard {
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# Constants
WEEKDAYS = {
    0: "Monday",
    1: "Tuesday", 
    2: "Wednesday",
    3: "Thursday",
    4: "Friday",
    5: "Saturday",
    6: "Sunday"
}

WEEKDAYS_CN = {
    "Monday": "æ˜ŸæœŸä¸€",
    "Tuesday": "æ˜ŸæœŸäºŒ",
    "Wednesday": "æ˜ŸæœŸä¸‰",
    "Thursday": "æ˜ŸæœŸå››",
    "Friday": "æ˜ŸæœŸäº”",
    "Saturday": "æ˜ŸæœŸå…­",
    "Sunday": "æ˜ŸæœŸæ—¥"
}

# Load Data
@st.cache_data
def load_data():
    try:
        df = pd.read_csv("schedule_data.csv")
        return df
    except FileNotFoundError:
        st.error("æœªæ‰¾åˆ°è¯¾ç¨‹è¡¨æ•°æ®æ–‡ä»¶ (schedule_data.csv)ã€‚è¯·åœ¨ä¾§è¾¹æ ä¸Šä¼ æˆ–æ£€æŸ¥æ–‡ä»¶è·¯å¾„ã€‚")
        return pd.DataFrame(columns=["day", "period", "start_time", "end_time", "course_name", "location", "teacher"])

def save_data(df):
    df.to_csv("schedule_data.csv", index=False)
    st.cache_data.clear()

# Core Logic: Get Current Status and Next Class
def get_status_and_next_class(df):
    now = datetime.now()
    # now = datetime.strptime("2023-10-23 09:00", "%Y-%m-%d %H:%M") # Debugging
    current_weekday_en = WEEKDAYS[now.weekday()]
    current_time_str = now.strftime("%H:%M")
    
    # Filter for today
    today_classes = df[df['day'] == current_weekday_en].copy()
    
    if today_classes.empty:
        return "Free", "ä»Šå¤©æ²¡æœ‰è¯¾ï¼Œå¥½å¥½ä¼‘æ¯å§ï¼", None

    # Sort by time
    today_classes = today_classes.sort_values("start_time")
    
    current_status = "Free"
    status_msg = "å½“å‰ç©ºé—²"
    next_class = None
    
    for index, row in today_classes.iterrows():
        start = row['start_time']
        end = row['end_time']
        
        if start <= current_time_str <= end:
            current_status = "In Class"
            status_msg = f"æ­£åœ¨ä¸Šè¯¾ï¼š{row['course_name']} ({row['location']})"
            # Find next class after this one
            remaining_classes = today_classes[today_classes['start_time'] > end]
            if not remaining_classes.empty:
                next_class = remaining_classes.iloc[0]
            return current_status, status_msg, next_class
        
        if start > current_time_str:
            # This is the next class
            current_status = "Upcoming"
            time_diff = datetime.strptime(start, "%H:%M") - datetime.strptime(current_time_str, "%H:%M")
            # Handle negative days if any logic weirdness (shouldn't happen here)
            if time_diff.days < 0: time_diff = timedelta(days=0, seconds=time_diff.seconds)
            
            minutes_left = int(time_diff.total_seconds() / 60)
            status_msg = f"è·ç¦»ä¸‹èŠ‚è¯¾è¿˜æœ‰ {minutes_left} åˆ†é’Ÿ"
            next_class = row
            return current_status, status_msg, next_class

    return "Done", "ä»Šå¤©çš„è¯¾ç¨‹å…¨éƒ¨ç»“æŸäº†ï¼", None

# AI Logic: Smart Query
def smart_search(query, df):
    if not query:
        return pd.DataFrame()
    
    # Create a search string for each row
    df['search_content'] = df.apply(lambda x: f"{x['day']} {x['course_name']} {x['teacher']} {x['location']}", axis=1)
    
    # Simple keyword matching first
    results = df[df['search_content'].str.contains(query, case=False, na=False)]
    
    # If no exact match, try fuzzy
    if results.empty:
        # Get best matches for course name
        choices = df['course_name'].unique().tolist()
        best_matches = process.extract(query, choices, limit=3, scorer=fuzz.partial_ratio)
        matched_courses = [m[0] for m in best_matches if m[1] > 60]
        
        if matched_courses:
            results = df[df['course_name'].isin(matched_courses)]
        else:
            # Try fuzzy match on teacher
            choices_teacher = df['teacher'].unique().tolist()
            best_matches_teacher = process.extract(query, choices_teacher, limit=3, scorer=fuzz.partial_ratio)
            matched_teachers = [m[0] for m in best_matches_teacher if m[1] > 60]
            if matched_teachers:
                results = df[df['teacher'].isin(matched_teachers)]

    return results.drop(columns=['search_content'], errors='ignore')

# AI Persona Response
def get_ai_response(query_text, context_data=None):
    """
    Super Smart Local Logic (Rule-based)
    Generates human-like responses based on time, course load, and query type without external API.
    """
    import random
    
    # 1. Analyze the context (is it empty? has courses?)
    has_courses = False
    course_count = 0
    is_morning = False
    is_evening = False
    is_weekend = False
    
    # Simple parsing of context_data string
    if context_data and "è¯¥æ—¶æ®µæ— è¯¾" not in context_data and "æœªæ‰¾åˆ°åŒ¹é…è¯¾ç¨‹" not in context_data:
        has_courses = True
        # Estimate count by newlines
        course_count = len(context_data.strip().split('\n')) - 1 # minus header
        if course_count < 1: course_count = 1
        
        # Check time keywords in data
        if "08:" in context_data or "09:" in context_data: is_morning = True
        if "19:" in context_data or "20:" in context_data: is_evening = True
        if "Saturday" in context_data or "Sunday" in context_data: is_weekend = True

    # 2. Analyze User Query Intent
    query_lower = query_text.lower()
    is_greeting = any(k in query_lower for k in ["ä½ å¥½", "hello", "hi", "åœ¨å—"])
    is_conflict = any(k in query_lower for k in ["å†²çª", "ç©ºé—²", "æ²¡è¯¾", "æœ‰æ—¶é—´"])
    is_location = any(k in query_lower for k in ["åœ¨å“ª", "åœ°ç‚¹", "æ•™å®¤"])
    is_exam = any(k in query_lower for k in ["è€ƒè¯•", "å¤ä¹ "])
    
    # 3. Generate Response Logic
    
    # Case A: Greeting
    if is_greeting:
        return random.choice([
            "ğŸ‘‹ ä½ å¥½å‘€ï¼æˆ‘æ˜¯ä½ çš„æ™ºèƒ½è¯¾ç¨‹åŠ©æ‰‹ï¼Œéšæ—¶å¾…å‘½ï¼",
            "Hiï¼ä»Šå¤©æƒ³æŸ¥ç‚¹ä»€ä¹ˆï¼Ÿè¯¾è¡¨è¿˜æ˜¯ç©ºé—²æ—¶é—´ï¼Ÿ",
            "æˆ‘åœ¨å‘¢ï¼è™½ç„¶æˆ‘æ˜¯ä¸ªæœºå™¨äººï¼Œä½†æˆ‘ä¼šä¸€ç›´é™ªç€ä½ å­¦ä¹ çš„ï¼ğŸ¤–"
        ])

    # Case B: No Courses Found (Free Time)
    if not has_courses:
        if is_conflict:
            return random.choice([
                "å¥½æ¶ˆæ¯ï¼è¿™æ®µæ—¶é—´å®Œå…¨ç©ºé—²ï¼Œæ²¡æœ‰ä»»ä½•å†²çªï¼Œæ”¾å¿ƒå®‰æ’ï¼ğŸ‰",
                "ç»è¿‡æ‰«æï¼Œæ­¤æ—¶æ®µæ— è¯¾ã€‚å»å›¾ä¹¦é¦†å·ä¸€ä¼šå„¿ï¼Œè¿˜æ˜¯å›å®¿èˆèººå¹³ï¼ŸğŸ›Œ",
                "å®Œç¾ï¼æ—¶é—´è¡¨ä¸€ç‰‡ç©ºç™½ï¼Œå±äºä½ çš„è‡ªç”±æ—¶é—´åˆ°äº†ï¼"
            ])
        else:
            return random.choice([
                "æŸ¥äº†ä¸€ä¸‹ï¼Œè¿™ä¸ªæ—¶é—´æ®µæ²¡æœ‰è¯¾å“¦ï¼å»å–æ¯å¥¶èŒ¶æ”¾æ¾ä¸€ä¸‹å§ï¼ğŸ¥¤",
                "å’¦ï¼Ÿå¥½åƒæ²¡è¯¾è€¶ã€‚æ˜¯ä¸æ˜¯è®°é”™æ—¶é—´äº†ï¼Œè¿˜æ˜¯è¿™å°±æ˜¯ä¼ è¯´ä¸­çš„â€œæ²¡è¯¾æ—¥â€ï¼ŸğŸ˜",
                "ç³»ç»Ÿæ˜¾ç¤ºæ— è¯¾ã€‚å»ºè®®åˆ©ç”¨è¿™æ®µæ—¶é—´é¢„ä¹ ä¸€ä¸‹ï¼ˆæˆ–è€…æ‰“æŠŠæ¸¸æˆï¼‰ï¼ŸğŸ®"
            ])

    # Case C: Has Courses (Busy)
    if has_courses:
        # Sub-case: Morning Classes
        if is_morning:
            msg = random.choice([
                f"æ—©èµ·çš„é¸Ÿå„¿æœ‰è™«åƒï¼ä¸Šåˆæœ‰ {course_count} èŠ‚è¯¾ï¼Œè®°å¾—åƒæ—©é¤å“¦ï¼ğŸ¥¯",
                f"æ—©å…«äººé›†åˆï¼ä¸Šåˆ {course_count} èŠ‚ç¡¬ä»—è¦æ‰“ï¼Œå¸¦å¥½æ°´æ¯å’Œä¹¦æœ¬ï¼ğŸ“š",
                "ä¸€æ—¥ä¹‹è®¡åœ¨äºæ™¨ï¼Œä¸Šåˆçš„è¯¾è™½ç„¶å¤šï¼Œä½†ä½ å¯ä»¥çš„ï¼åŠ æ²¹ï¼ğŸ’ª"
            ])
            return msg
            
        # Sub-case: Evening Classes
        if is_evening:
            msg = random.choice([
                f"è¾›è‹¦å•¦ï¼æ™šä¸Šè¿˜æœ‰ {course_count} èŠ‚è¯¾ã€‚åšæŒä¸€ä¸‹ï¼Œä¸‹è¯¾å°±èƒ½åƒå¤œå®µäº†ï¼ğŸ¢",
                "å¤œè‰²æ¸©æŸ”ï¼Œä½†ä½ è¿˜å¾—å»ä¸Šè¯¾... æ™šä¸Šæ³¨æ„å®‰å…¨å“¦ï¼",
                "æ™šè¯¾è™½ç„¶ç´¯ï¼Œä½†ä¹Ÿæ˜¯å¼¯é“è¶…è½¦çš„å¥½æœºä¼šï¼å†²é¸­ï¼ğŸ¦†"
            ])
            return msg
            
        # Sub-case: Many Classes (>=3)
        if course_count >= 3:
            msg = random.choice([
                f"å¤©å“ªï¼ŒæŸ¥åˆ°äº† {course_count} èŠ‚è¯¾ï¼è¿™å¯æ˜¯ç‰¹ç§å…µçš„ä¸€å¤©ï¼ŒæŒºä½ï¼ğŸ›¡ï¸",
                f"è¯¾è¡¨æ»¡æ»¡å½“å½“çš„ ({course_count} èŠ‚)ï¼Œæ˜¯å……å®çš„ä¸€å¤©å‘¢ï¼æ³¨æ„åŠ³é€¸ç»“åˆã€‚",
                "è¿™ä¹ˆå¤šè¯¾... æ‘¸æ‘¸å¤´ï¼Œä¸Šå®Œå¥–åŠ±è‡ªå·±ä¸€é¡¿å¤§é¤å§ï¼ğŸ²"
            ])
            return msg
            
        # Sub-case: Location Query
        if is_location:
            return f"å¸®ä½ æ‰¾åˆ°äº†ï¼å°±åœ¨è¡¨æ ¼é‡Œå†™ç€å‘¢ï¼Œåˆ«è·‘é”™æ•™å®¤å•¦ï¼ğŸƒâ€â™‚ï¸"

        # Default Busy Response
        return random.choice([
            f"æ”¶åˆ°ï¼ä¸ºæ‚¨æŸ¥åˆ°äº† {course_count} èŠ‚è¯¾çš„ä¿¡æ¯ï¼Œè¯¦æƒ…è¯·çœ‹ä¸‹æ–¹è¡¨æ ¼ã€‚ğŸ‘‡",
            f"ç›®æ ‡é”å®šï¼æœ‰ {course_count} èŠ‚è¯¾æ­£åœ¨ç­‰ç€ä½ ã€‚å‡†å¤‡å¥½å»ä¸Šè¯¾äº†å—ï¼Ÿ",
            "æ•°æ®æ£€ç´¢å®Œæ¯•ã€‚çœ‹æ¥æ˜¯ä¸èƒ½å·æ‡’äº†ï¼Œå¿«å»æ•™å®¤å åº§å§ï¼ğŸ’º"
        ])

    # Fallback
    return "è™½ç„¶æˆ‘ä¸ç¡®å®šä½ åœ¨è¯´ä»€ä¹ˆï¼Œä½†æˆ‘è¿˜æ˜¯å°½åŠ›å¸®ä½ æ‰¾äº†æ‰¾è¯¾è¡¨... çœ‹çœ‹ä¸‹é¢æœ‰æ²¡æœ‰ï¼Ÿ"

# Visualization Logic
def plot_course_stats(df):
    if df.empty:
        return
    
    # Data Preparation
    total_courses = len(df)
    day_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
    
    # 1. Heatmap Data (Day vs Period)
    # Ensure 'period' is numeric for sorting, then convert to string for display if needed
    heatmap_df = df.copy()
    heatmap_df['day_idx'] = heatmap_df['day'].apply(lambda x: day_order.index(x) if x in day_order else 7)
    heatmap_df['day_cn'] = heatmap_df['day'].map(WEEKDAYS_CN)
    
    # 2. Course Distribution Data (Pie Chart)
    course_counts = df['course_name'].value_counts().reset_index()
    course_counts.columns = ['course_name', 'count']
    
    return heatmap_df, course_counts, total_courses

# --- UI ---

st.title("ğŸ“ æ ¡å›­è¯¾ç¨‹è¡¨æ™ºèƒ½åŠ©æ‰‹")

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ è¯¾ç¨‹ç®¡ç†")
    uploaded_file = st.file_uploader("ä¸Šä¼ è¯¾ç¨‹è¡¨ (CSV)", type="csv")
    if uploaded_file is not None:
        try:
            new_df = pd.read_csv(uploaded_file)
            save_data(new_df)
            st.success("è¯¾ç¨‹è¡¨æ›´æ–°æˆåŠŸï¼")
            st.rerun()
        except Exception as e:
            st.error(f"ä¸Šä¼ å¤±è´¥: {e}")
            
    st.info("ğŸ’¡ æç¤ºï¼šæ”¯æŒè‡ªç„¶è¯­è¨€æœç´¢ï¼Œä¾‹å¦‚ 'å‘¨äº”çš„è¯¾' æˆ– 'é«˜æ•°åœ¨å“ªä¸Š'ã€‚")
    st.markdown("---")
    st.markdown("**å½“å‰æ—¶é—´**")
    st.write(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    if st.button("åˆ·æ–°çŠ¶æ€"):
        st.cache_data.clear()
        st.rerun()

# Main Content
df = load_data()

# Tabs for different features
tab1, tab2, tab3 = st.tabs(["ğŸ  é¦–é¡µæ¦‚è§ˆ", "ğŸ¤– æ™ºèƒ½åŠ©æ‰‹", "ğŸ“Š å­¦æƒ…åˆ†æ"])

with tab1:
    # 1. Smart Status Section
    st.header("ğŸ“Œ å®æ—¶çŠ¶æ€")
    status, msg, next_cls = get_status_and_next_class(df)

    col1, col2 = st.columns([2, 1])

    with col1:
        if status == "In Class":
            st.error(f"ğŸ”´ {msg}")
        elif status == "Upcoming":
            st.warning(f"ğŸŸ¡ {msg}")
        elif status == "Free":
            st.success(f"ğŸŸ¢ {msg}")
        else: # Done
            st.success(f"ğŸŒ™ {msg}")

    if next_cls is not None:
        with col2:
            st.markdown("#### ä¸‹èŠ‚è¯¾è¯¦æƒ…")
            st.markdown(f"**è¯¾ç¨‹:** {next_cls['course_name']}")
            st.markdown(f"**åœ°ç‚¹:** {next_cls['location']}")
            st.markdown(f"**æ—¶é—´:** {next_cls['start_time']} - {next_cls['end_time']}")
            st.markdown(f"**è€å¸ˆ:** {next_cls['teacher']}")

    st.markdown("---")
    
    # 3. Weekly Schedule View
    st.header("ğŸ“… æœ¬å‘¨è¯¾è¡¨")
    try:
        # Add a sorter for days
        day_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
        df['day'] = pd.Categorical(df['day'], categories=day_order, ordered=True)
        
        # Ensure consistency between tab labels and content iteration
        days_present = [d for d in day_order if d in df['day'].unique()]
        tabs = st.tabs([WEEKDAYS_CN[d] for d in days_present])
        
        for i, day in enumerate(days_present):
            with tabs[i]:
                day_data = df[df['day'] == day].sort_values('start_time')
                for _, row in day_data.iterrows():
                    with st.container():
                        c1, c2, c3 = st.columns([1, 2, 1])
                        c1.write(f"**{row['start_time']} - {row['end_time']}**")
                        c2.write(f"**{row['course_name']}**")
                        c3.write(f"ğŸ“ {row['location']}")
                        st.divider()
    except Exception as e:
        st.error(f"è¯¾è¡¨æ˜¾ç¤ºå‡ºé”™: {e}")
        st.dataframe(df)

with tab2:
    st.header("ğŸ¤– AI æ™ºèƒ½æŸ¥è¯¢")
    
    # Chat interface style
    st.markdown("""
    <div style="background-color:#f0f2f6;padding:10px;border-radius:10px;margin-bottom:20px;">
        <p>ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„è¯¾ç¨‹åŠ©æ‰‹ã€‚ä½ å¯ä»¥é—®æˆ‘ï¼š</p>
        <ul>
            <li>â€œæ˜å¤©æœ‰ä»€ä¹ˆè¯¾ï¼Ÿâ€</li>
            <li>â€œé«˜æ•°åœ¨å“ªä¸Šï¼Ÿâ€</li>
            <li>â€œå‘¨äº”ä¸‹åˆç©ºé—²å—ï¼Ÿâ€ï¼ˆå†²çªæ£€æµ‹ï¼‰</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    query = st.text_input("è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹:", placeholder="ä¾‹å¦‚ï¼šæ˜å¤©ä¸Šåˆæœ‰è¯¾å—ï¼Ÿ")

    if query:
        # Check for conflict detection keywords
        is_conflict_check = any(k in query for k in ["ç©ºé—²", "æ²¡è¯¾", "æœ‰æ—¶é—´", "å†²çª"])
        
        # Enhanced Time Logic
        time_period = None
        if "ä¸Šåˆ" in query: time_period = "morning"
        elif "ä¸‹åˆ" in query: time_period = "afternoon"
        elif "æ™šä¸Š" in query or "æ™šè¯¾" in query: time_period = "evening"

        # Special handling for time keywords
        search_df = df.copy()
        target_day = None
        
        # Enhanced Date Logic
        if "ä»Šå¤©" in query:
            target_day = WEEKDAYS[datetime.now().weekday()]
        elif "æ˜å¤©" in query:
            target_day = WEEKDAYS[(datetime.now().weekday() + 1) % 7]
        elif "åå¤©" in query:
            target_day = WEEKDAYS[(datetime.now().weekday() + 2) % 7]
        elif "ä¸‹å‘¨" in query:
             # Just a simple response for "next week" as user likely means generic schedule
            pass 
        elif "å‘¨ä¸€" in query or "æ˜ŸæœŸä¸€" in query: target_day = "Monday"
        elif "å‘¨äºŒ" in query or "æ˜ŸæœŸäºŒ" in query: target_day = "Tuesday"
        elif "å‘¨ä¸‰" in query or "æ˜ŸæœŸä¸‰" in query: target_day = "Wednesday"
        elif "å‘¨å››" in query or "æ˜ŸæœŸå››" in query: target_day = "Thursday"
        elif "å‘¨äº”" in query or "æ˜ŸæœŸäº”" in query: target_day = "Friday"
        elif "å‘¨å…­" in query or "æ˜ŸæœŸå…­" in query: target_day = "Saturday"
        elif "å‘¨æ—¥" in query or "æ˜ŸæœŸæ—¥" in query: target_day = "Sunday"
        
        result_df = pd.DataFrame()
        ai_msg = ""
        
        if "ä¸‹å‘¨" in query:
             ai_msg = get_ai_response(query, "ç”¨æˆ·è¯¢é—®ä¸‹å‘¨è¯¾è¡¨ï¼Œå‘ŠçŸ¥é€šå¸¸ä¸æœ¬å‘¨ä¸€è‡´")
             # Show full schedule
             result_df = search_df
        elif target_day:
            result_df = search_df[search_df['day'] == target_day]
            
            # Filter by time period if specified
            if time_period:
                if time_period == "morning":
                    result_df = result_df[result_df['start_time'] < "12:00"]
                elif time_period == "afternoon":
                    result_df = result_df[(result_df['start_time'] >= "12:00") & (result_df['start_time'] < "18:00")]
                elif time_period == "evening":
                    result_df = result_df[result_df['start_time'] >= "18:00"]

            # Use Real AI to generate response based on data
            data_context = result_df.to_string(index=False) if not result_df.empty else "è¯¥æ—¶æ®µæ— è¯¾"
            ai_msg = get_ai_response(query, data_context)

        else:
            result_df = smart_search(query, search_df)
            data_context = result_df.to_string(index=False) if not result_df.empty else "æœªæ‰¾åˆ°åŒ¹é…è¯¾ç¨‹"
            ai_msg = get_ai_response(query, data_context)
        
        # Display AI Message
        st.success(f"ğŸ¤– AI: {ai_msg}")
        
        if not result_df.empty:
            # Formatting for display
            display_df = result_df.copy()
            display_df['day'] = display_df['day'].map(WEEKDAYS_CN)
            # Rename columns to Chinese
            display_df = display_df.rename(columns={
                "day": "æ˜ŸæœŸ",
                "start_time": "å¼€å§‹æ—¶é—´",
                "end_time": "ç»“æŸæ—¶é—´",
                "course_name": "è¯¾ç¨‹åç§°",
                "location": "ä¸Šè¯¾åœ°ç‚¹",
                "teacher": "ä»»è¯¾æ•™å¸ˆ"
            })
            st.dataframe(display_df[['æ˜ŸæœŸ', 'å¼€å§‹æ—¶é—´', 'è¯¾ç¨‹åç§°', 'ä¸Šè¯¾åœ°ç‚¹', 'ä»»è¯¾æ•™å¸ˆ']], use_container_width=True)

with tab3:
    st.header("ğŸ“Š å­¦æƒ…æ•°æ®åˆ†æ")
    
    heatmap_df, course_counts, total_courses = plot_course_stats(df)
    
    # Metrics
    m1, m2, m3 = st.columns(3)
    m1.metric("æœ¬å‘¨è¯¾ç¨‹æ€»æ•°", f"{total_courses} èŠ‚", "+2 (å¯¹æ¯”ä¸Šå‘¨)")
    
    # Calculate busiest day
    if not heatmap_df.empty:
        busiest_day_en = heatmap_df['day'].value_counts().idxmax()
        busiest_count = heatmap_df['day'].value_counts().max()
        m2.metric("æœ€å¿™çš„ä¸€å¤©", WEEKDAYS_CN.get(busiest_day_en, busiest_day_en), f"{busiest_count} èŠ‚è¯¾")
    else:
        m2.metric("æœ€å¿™çš„ä¸€å¤©", "-", "0 èŠ‚")
        
    m3.metric("å¹³å‡æ¯æ—¥è¯¾ç¨‹", f"{total_courses/5:.1f} èŠ‚")
    
    st.markdown("---")
    
    col_viz1, col_viz2 = st.columns([1.5, 1])
    
    with col_viz1:
        st.markdown("### ğŸŒ¡ï¸ è¯¾ç¨‹åˆ†å¸ƒçƒ­åŠ›å›¾")
        if not heatmap_df.empty:
            # Create shortened course names for display
            heatmap_df['short_name'] = heatmap_df['course_name'].apply(lambda x: x[:4] + '...' if len(x) > 4 else x)
            
            # Base chart
            base = alt.Chart(heatmap_df).encode(
                x=alt.X('day_cn:N', title=None, sort=["æ˜ŸæœŸä¸€", "æ˜ŸæœŸäºŒ", "æ˜ŸæœŸä¸‰", "æ˜ŸæœŸå››", "æ˜ŸæœŸäº”", "æ˜ŸæœŸå…­", "æ˜ŸæœŸæ—¥"], axis=alt.Axis(labelAngle=0)),
                y=alt.Y('period:O', title='èŠ‚æ¬¡', sort='ascending', axis=alt.Axis(titleAngle=0, titleAlign="right", titleY=15)),
            ).properties(
                height=400,
                width='container'
            )

            # Rectangles for background color
            rects = base.mark_rect(cornerRadius=5).encode(
                color=alt.Color('course_name:N', legend=None),
                tooltip=[
                    alt.Tooltip('day_cn', title='æ˜ŸæœŸ'),
                    alt.Tooltip('period', title='èŠ‚æ¬¡'),
                    alt.Tooltip('course_name', title='è¯¾ç¨‹åç§°'),
                    alt.Tooltip('location', title='ä¸Šè¯¾åœ°ç‚¹'),
                    alt.Tooltip('teacher', title='ä»»è¯¾æ•™å¸ˆ')
                ]
            )

            # Text labels for course names
            text = base.mark_text(baseline='middle', size=10, color='white').encode(
                text=alt.Text('short_name'),
                color=alt.value('white')
            )

            # Combine
            st.altair_chart(rects + text, use_container_width=True)
        else:
            st.info("æš‚æ— æ•°æ®")

    with col_viz2:
        st.markdown("### ğŸ© è¯¾ç¨‹æ•°é‡åˆ†å¸ƒ")
        if not course_counts.empty:
            base = alt.Chart(course_counts).encode(
                theta=alt.Theta("count", stack=True)
            )
            pie = base.mark_arc(outerRadius=100, innerRadius=60).encode(
                color=alt.Color("course_name", legend=None),
                order=alt.Order("count", sort="descending"),
                tooltip=[
                    alt.Tooltip('course_name', title='è¯¾ç¨‹åç§°'),
                    alt.Tooltip('count', title='èŠ‚æ•°')
                ]
            )
            text = base.mark_text(radius=120).encode(
                text="count",
                order=alt.Order("count", sort="descending"),
                color=alt.value("black") 
            )
            st.altair_chart(pie + text, use_container_width=True)
        else:
            st.info("æš‚æ— æ•°æ®")

